{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "YOLO-mafa-dataset",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.12 64-bit ('directml': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "b79731b8eece84f7cb354a4bd2059b99adf53cad41c8af6ff1a9c83d4e8f4ed4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjlallana/MAFAtoYOLO/blob/main/YOLO_mafa_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparar el dataset"
      ],
      "metadata": {
        "id": "7mGmQbAO5pQb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# google colab gpu\n",
        "import torch\n",
        "print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
        "!rm -r /content/sample_data"
      ],
      "outputs": [],
      "metadata": {
        "id": "YWCvFEgxA40x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descargar el script para pasar las anotaciones del formato propio que usa el dataset MAFA al formato que usa YOLO"
      ],
      "metadata": {
        "id": "Gt3TQfLRn4qC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!git clone https://rjlallana@github.com/rjlallana/MAFAtoYOLO.git\n",
        "%cd /content/MAFAtoYOLO/"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MAFAtoYOLO' already exists and is not an empty directory.\n",
            "/content/MAFAtoYOLO\n"
          ]
        }
      ],
      "metadata": {
        "id": "KhNASO2-BuQF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c9db81-7b15-44ae-9d20-abb766bd6748"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descargar el dataset MAFA"
      ],
      "metadata": {
        "id": "drz0UOqAa7Ni"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%cd /content/MAFAtoYOLO\n",
        "!gdown --id 1uN0a4P0wAFwJLid_r7VHFs0KUcizIRGN # train labels\n",
        "!gdown --id 1Fu1C1O8ok-Z7r8XSWoTb9yB_2_5w6BDt # test labels\n",
        "!gdown --id 17bRIiaGyrKLEDQOV2RlqbPQ9TyCZxq9k # train images\n",
        "!gdown --id 1jJHdmmscqxvNQ2dxKUrLaHqW3w1Yo_9S # test images"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MAFAtoYOLO\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uN0a4P0wAFwJLid_r7VHFs0KUcizIRGN\n",
            "To: /content/MAFAtoYOLO/MAFA-Label-Test.zip\n",
            "100% 182k/182k [00:00<00:00, 5.69MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Fu1C1O8ok-Z7r8XSWoTb9yB_2_5w6BDt\n",
            "To: /content/MAFAtoYOLO/MAFA-Label-Train.zip\n",
            "100% 947k/947k [00:00<00:00, 15.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17bRIiaGyrKLEDQOV2RlqbPQ9TyCZxq9k\n",
            "To: /content/MAFAtoYOLO/train-images.zip\n",
            "1.96GB [00:20, 94.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jJHdmmscqxvNQ2dxKUrLaHqW3w1Yo_9S\n",
            "To: /content/MAFAtoYOLO/test-images.zip\n",
            "466MB [00:06, 69.9MB/s]\n"
          ]
        }
      ],
      "metadata": {
        "id": "Knxi2ncxWffW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e989ce0-3c19-4e7b-ba59-366d31dad557"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descomprimir los archivos y borrar los .zip"
      ],
      "metadata": {
        "id": "zTgWxqKNn4qE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!unzip -qq MAFA-Label-Test.zip\n",
        "!unzip -qq MAFA-Label-Train.zip\n",
        "!unzip -qq test-images.zip -d test\n",
        "!unzip -qq train-images.zip -d train\n",
        "!rm *.zip\n",
        "!rm *.txt"
      ],
      "outputs": [],
      "metadata": {
        "id": "QaXtHyKQM1YK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crear el archivo de configuaracion del Dataset\n",
        "Este archivo YAML describe la estructura de directorios del dataset.\n",
        "* Cada ruta en train, val, test lleva a una carpeta con un fichero de texto con las rutas las imagenes que usa.\n",
        "* El numero de clases (nc)\n",
        "* Y una lista de los nombres de las clases\n"
      ],
      "metadata": {
        "id": "d32N92A4Ac_l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "yaml = \"\"\"\\\n",
        "train: ../MAFAtoYOLO/train/\n",
        "val: ../MAFAtoYOLO/val/\n",
        "test: ../MAFAtoYOLO/test/\n",
        "\n",
        "nc: 3\n",
        "names: ['No mask', 'Mask', 'Mask incorrect']\n",
        "\"\"\"\n",
        "with open('/content/MAFAtoYOLO/mafa.yaml', 'w') as writefile:\n",
        "    writefile.write(yaml)\n",
        "\n",
        "!cat /content/MAFAtoYOLO/mafa.yaml"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: ../MAFAtoYOLO/train/\n",
            "val: ../MAFAtoYOLO/val/\n",
            "test: ../MAFAtoYOLO/test/\n",
            "\n",
            "nc: 3\n",
            "names: ['No mask', 'Mask', 'Mask incorrect']\n"
          ]
        }
      ],
      "metadata": {
        "id": "aJRXGMBQDBMZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46855f85-a6d3-4b06-a2df-1090de4b27df"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejecucion del script \n",
        "Pasar las anotaciones del formato propio que usa el dataset MAFA al formato que usa YOLO"
      ],
      "metadata": {
        "id": "SJmDtJU4n4qH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "!ls"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LabelTestAll.mat   MAFA.zip\t  YOLO_mafa_dataset_colab.ipynb  images   test\n",
            "LabelTrainAll.mat  MAFAtoYOLO.7z  YOLO_mafa_dataset_wsl.ipynb\t main.py  train\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "!python main.py"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 582, in <module>\n",
            "    main()\n",
            "  File \"main.py\", line 475, in main\n",
            "    create_yolo_structure()\n",
            "  File \"main.py\", line 421, in create_yolo_structure\n",
            "    os.mkdir('images')\n",
            "FileExistsError: [Errno 17] File exists: 'images'\n"
          ]
        }
      ],
      "metadata": {
        "id": "UGMGn4AnV-2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66141ea9-4a92-4ead-be77-137ce9e87e3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descargar el modelo YOLO"
      ],
      "metadata": {
        "id": "UwJx-2NHsYxT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/rjlallana/yolo\n",
        "!pip install -qr yolo/requirements.txt"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'yolo'...\n",
            "remote: Enumerating objects: 401, done.\u001b[K\n",
            "remote: Total 401 (delta 0), reused 0 (delta 0), pack-reused 401\u001b[K\n",
            "Receiving objects: 100% (401/401), 2.96 MiB | 31.94 MiB/s, done.\n",
            "Resolving deltas: 100% (186/186), done.\n",
            "\u001b[K     |████████████████████████████████| 636 kB 27.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 776.7 MB 4.4 kB/s \n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 87 kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 40.1 MB/s \n",
            "\u001b[?25h  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.7.0 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "metadata": {
        "id": "Ie5uLDH4uzAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db93bdf-aabc-40a2-af39-994426d46eae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por defecto Google Colab tiene una version más reciente de TensorFlow que la que usa el modelo de YOLO implementado, y a la hora de entrenar el modelo en esta versión falla.\n",
        "Por lo tanto descargamos una version anterior, downgrade: ``pytorch 1.8.0+cu101 -> 1.7.1+cu101``\n"
      ],
      "metadata": {
        "id": "bJn0NxY6n4qI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Downgrade pytorch 1.8.0+cu101 -> 1.7.1+cu101\r\n",
        "!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\r\n",
        "\r\n",
        "import torch \r\n",
        "print(torch.__version__)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torch-1.7.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (735.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 735.4 MB 14 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.8.2%2Bcu101-cp37-cp37m-linux_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 71 kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.7.2\n",
            "  Downloading torchaudio-0.7.2-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 20.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu101) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu101) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu101) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.7.0\n",
            "    Uninstalling torch-1.7.0:\n",
            "      Successfully uninstalled torch-1.7.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.8.1\n",
            "    Uninstalling torchvision-0.8.1:\n",
            "      Successfully uninstalled torchvision-0.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.7.1+cu101 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.7.1+cu101 torchaudio-0.7.2 torchvision-0.8.2+cu101\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu102\n"
          ]
        }
      ],
      "metadata": {
        "id": "qJxX0f0qNyW5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "4af24fb8-0b55-4679-cbf0-5f63e001c1e8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descargamos los pesos de la red entrenados en el dataset COCO para hacer transferencia de aprendizaje"
      ],
      "metadata": {
        "id": "a4SQ_kIFn4qJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%cd /content/yolo/weights\r\n",
        "!bash get_pretrain.sh"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolo/weights\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1871      0 --:--:-- --:--:-- --:--:--  1871\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  202M    0  202M    0     0  41.2M      0 --:--:--  0:00:04 --:--:-- 62.6M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2009      0 --:--:-- --:--:-- --:--:--  2009\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  142M    0  142M    0     0  60.1M      0 --:--:--  0:00:02 --:--:--  173M\n"
          ]
        }
      ],
      "metadata": {
        "id": "a-T9H2ZsClol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad12c62-babf-41c4-a371-8edd091c8ba9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenar el modelo para nuestro dataset"
      ],
      "metadata": {
        "id": "VUOiNLtMP5aG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaremos la herramienta online [wandb](https://wandb.ai/site) para recoger todos las metricas de nuestro modelo y poder visualizarlas mas tarde. "
      ],
      "metadata": {
        "id": "cll4CYFun4qJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# W&B API key: d0c1c5b12edb5a4b4ccceca771661a478bfd9efd\r\n",
        "%cd /content/yolo\r\n",
        "!pip --q install wandb # -qr requirements.txt  # install dependencies\r\n",
        "!wandb login"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolo\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 11.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 48.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 170 kB 51.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "metadata": {
        "id": "pgmS126mddCb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "136360e7-74c8-4ea5-9b52-3ffd569ec065"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entranamiento de nuestro Modelo para el dataset MAFA, a continuacion explicacmos cada parametro\n",
        "* ### --img: Tamaño de la imagen de entrada\n",
        "* ### --batch: Numero de batches en los que se divira nuestro dataset, en cada epoch se elige un batch diferente (Dataset = 1024, batch = 16 --> batches de 64 imagenes, cada epoch se procesan 64 imagenes ) [blog](https://towardsdatascience.com/how-to-break-gpu-memory-boundaries-even-with-large-batch-sizes-7a9c27a400ce)\n",
        "* ### --epochs: Numero total de veces que el modelo cambia sus pesos\n",
        "* ### --data: Archivo con la estructura del dataset\n",
        "* ### --cfg: Arquitectura del modelo\n",
        "* ### --weights: Pesos iniciales que usa el modelo\n",
        "* ### --hyp: Hyperparametros del modelo\n",
        "* ### --name: Nombre del proyecto"
      ],
      "metadata": {
        "id": "Ys-5hONtn4qK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%cd /content/yolo\n",
        "!python train.py --img 128 --batch 16 --epochs 20 --data '/content/MAFAtoYOLO/mafa.yaml' --weights './weights/yolov4_csp.pt' --hyp 'data/hyp.scratch.640.yaml' --cfg '/cfg/yolor_csp.cfg' --name yolov4_csp-mafa-old"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolo\n",
            "Using torch 1.7.1+cu101 CUDA:0 (Tesla K80, 11441MB)\n",
            "\n",
            "Namespace(adam=False, batch_size=16, bucket='', cache_images=False, cfg='./cfg/yolor_csp.cfg', data='/content/MAFAtoYOLO/mafa.yaml', device='', epochs=20, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.640.yaml', image_weights=False, img_size=[128, 128], local_rank=-1, log_imgs=16, multi_scale=False, name='yolov4_csp-mafa-old', noautoanchor=False, nosave=False, notest=False, project='runs/train', rect=False, resume=False, save_dir='runs/train/yolov4_csp-mafa-old', single_cls=False, sync_bn=False, total_batch_size=16, weights='./weights/yolov4_csp.pt', workers=8, world_size=1)\n",
            "Start Tensorboard with \"tensorboard --logdir runs/train\", view at http://localhost:6006/\n",
            "2021-08-14 11:16:32.873329: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Hyperparameters {'lr0': 0.01, 'lrf': 0.2, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 0.05, 'cls': 0.3, 'cls_pw': 1.0, 'obj': 0.7, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.9, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0}\n",
            "Model Summary: 529 layers, 52923994 parameters, 52923994 gradients, 120.636808800 GFLOPS\n",
            "Transferred 684/684 items from ./weights/yolov4_csp.pt\n",
            "Optimizer groups: 115 .bias, 115 conv.weight, 118 other\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgodrik\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "2021-08-14 11:16:43.739630: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov4_csp-mafa-old\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/godrik/PFG\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/godrik/PFG/runs/1f52vazt\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/yolo/wandb/run-20210814_111642-1f52vazt\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "Scanning images:  35% 3160/8962 [00:04<00:07, 819.21it/s]/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 4. \n",
            "  warnings.warn(str(msg))\n",
            "Scanning images: 100% 8962/8962 [00:10<00:00, 895.91it/s] \n",
            "Scanning labels ../MAFAtoYOLO/train/labels.cache3 (8962 found, 0 missing, 0 empty, 0 duplicate, for 8962 images): 8962it [00:01, 6243.88it/s]\n",
            "Scanning images:  23% 1151/4935 [00:01<00:06, 626.59it/s]/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "Scanning images: 100% 4935/4935 [00:05<00:00, 896.47it/s] \n",
            "Scanning labels ../MAFAtoYOLO/test/labels.cache3 (4935 found, 0 missing, 0 empty, 0 duplicate, for 4935 images): 4935it [00:00, 6329.71it/s]\n",
            "NumExpr defaulting to 2 threads.\n",
            "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
            "Image sizes 128 train, 128 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/yolov4_csp-mafa-old\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "      0/19     3.71G   0.05484     0.155  0.002397    0.2122        48       128:  48% 268/561 [02:27<02:31,  1.93it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
            "      0/19     3.71G    0.0488    0.1426  0.001807    0.1932        58       128:  84% 472/561 [04:06<00:36,  2.41it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
            "      0/19     3.51G   0.04736     0.142  0.001663    0.1911         2       128: 100% 561/561 [04:49<00:00,  1.94it/s]\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "      1/19     3.71G   0.04059    0.1283 0.0008276    0.1697        43       128:  48% 269/561 [02:21<02:14,  2.17it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
            "      1/19     3.71G    0.0411    0.1278  0.000826    0.1697        36       128:  70% 395/561 [03:20<01:18,  2.12it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
            "      1/19     3.71G   0.04172    0.1297  0.000819    0.1722         5       128: 100% 561/561 [04:34<00:00,  2.04it/s]\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "      2/19     3.71G   0.04218    0.1215  0.000754    0.1645        45       128:   1% 4/561 [00:01<04:45,  1.95it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
            "      2/19     3.71G   0.04351    0.1323 0.0008006    0.1767        49       128:  27% 154/561 [01:18<03:27,  1.96it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 537, in <module>\n",
            "    train(hyp, opt, device, tb_writer, wandb)\n",
            "  File \"train.py\", line 293, in train\n",
            "    scaler.scale(loss).backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/tensor.py\", line 221, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 132, in backward\n",
            "    allow_unreachable=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1191\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 255.  Press ctrl-c to abort syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/yolo/wandb/run-20210814_111642-1f52vazt/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/yolo/wandb/run-20210814_111642-1f52vazt/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               _runtime 667\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             _timestamp 1628940469\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  _step 27\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss 0.04172\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss 0.12967\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss 0.00082\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 0.00663\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 0.00663\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 0.04002\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               _runtime ▁▁▄▄▄▄▄▄▄▄▄▄▄▄▄█████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             _timestamp ▁▁▄▄▄▄▄▄▄▄▄▄▄▄▄█████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  _step ▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss █▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss █▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss █▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision ▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall ▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 ▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 ▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss ▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss ▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss ▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 ▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 ▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 █▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 5 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33myolov4_csp-mafa-old\u001b[0m: \u001b[34mhttps://wandb.ai/godrik/PFG/runs/1f52vazt\u001b[0m\n"
          ]
        }
      ],
      "metadata": {
        "id": "09CbhNi98mJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edd10684-b6b6-4dd7-97f6-f81bf70af0ba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dowload weights locally to resume the training"
      ],
      "metadata": {
        "id": "_Xl9jSOGZ2ke"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!zip -r /content/last.zip /content/yolo/runs/train/yolov4_csp-mafa-old/weights/last.pt"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/yolo/runs/train/yolov4_csp-mafa-old/weights/last.pt (deflated 7%)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMrB9ebwZ50q",
        "outputId": "66f42cd5-ac38-4c14-f2e1-c08d1beec862"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/last.zip\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  "
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": "download(\"download_2324448f-5b2b-421b-9144-f97585cfabc2\", \"last.zip\", 393387518)"
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DDcucmXAaSpd",
        "outputId": "648324e7-bb7d-4014-fd87-c694be9e9c47"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!ls -lh /content/last.zip"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 376M Aug 14 11:38 /content/last.zip\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn8sLPHKcpzf",
        "outputId": "7ee692a6-83b1-46d9-f976-70763be9a0a4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluación del rendimiento del modelo una vez acabado el entranamiento"
      ],
      "metadata": {
        "id": "kJVs_4zEeVbF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kvPUKWPGn4qL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolov5s_results`. (If given no name, it defaults to `results.txt`.) The results file is plotted as a png after training completes.\n",
        "\n",
        "Note from Glenn: Partially completed `results.txt` files can be plotted with `from utils.utils import plot_results; plot_results()`."
      ],
      "metadata": {
        "id": "7KN5ghjE6ZWh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "outputs": [],
      "metadata": {
        "id": "bOy5KI2ncnWd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# we can also output some older school graphs if the tensor board isn't working for whatever reason... \n",
        "#from utils.general import plot_results  # plot results.txt as results.png\n",
        "from IPython.display import Image, display\n",
        "display(Image('/content/ScaledYOLOv4/runs/exp0_yolov4-csp-results/results.png'))  # view results.png"
      ],
      "outputs": [],
      "metadata": {
        "id": "C60XAsyv6OPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Curious? Visualize Our Training Data with Labels\n",
        "\n",
        "After training starts, view `train*.jpg` images to see training images, labels and augmentation effects.\n",
        "\n",
        "Note a mosaic dataloader is used for training (shown below), a new dataloading concept developed by Glenn Jocher and first featured in [YOLOv4](https://arxiv.org/abs/2004.10934)."
      ],
      "metadata": {
        "id": "DLI1JmHU7B0l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# first, display our ground truth data\n",
        "print(\"GROUND TRUTH TRAINING DATA:\")\n",
        "Image(filename='/content/ScaledYOLOv4/runs/exp0_yolov4-csp-results/test_batch0_gt.jpg', width=900)"
      ],
      "outputs": [],
      "metadata": {
        "id": "PF9MLHDb7tB6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# print out an augmented training example\n",
        "print(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\n",
        "Image(filename='/content/ScaledYOLOv4/runs/exp0_yolov4-csp-results/train_batch0.jpg', width=900)"
      ],
      "outputs": [],
      "metadata": {
        "id": "W40tI99_7BcH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Save weights\n",
        "from google.colab import files\n",
        "files.download('/content/ScaledYOLOv4/runs/exp0_yolov4-csp-results/weights/best_yolov4-csp-results.pt') "
      ],
      "outputs": [],
      "metadata": {
        "id": "cFX1EIej-3iK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run Inference  With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
      ],
      "metadata": {
        "id": "N3qM6T0W53gh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# trained weights are saved by default in our weights folder\n",
        "%ls runs/"
      ],
      "outputs": [],
      "metadata": {
        "id": "yIEwt5YLeQ7P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%ls ./runs/exp0_yolov4-csp-results/weights"
      ],
      "outputs": [],
      "metadata": {
        "id": "4SyOWS80qR32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rRhZmqhMqQtQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# when we ran this, we saw .007 second inference time. That is 140 FPS on a TESLA P100!\n",
        "# use the best weights!\n",
        "%cd /content/ScaledYOLOv4/\n",
        "!python detect.py --weights /content/ScaledYOLOv4/runs/exp0_yolov4-csp-results/weights/best_yolov4-csp-results.pt --img 640 --conf 0.4 --source ../MAFAtoYOLO/test/images"
      ],
      "outputs": [],
      "metadata": {
        "id": "9nmZZnWOgJ2S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#display inference on ALL test images\n",
        "#this looks much better with longer training above\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('./inference/output/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "odKEqYtTgbRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export Trained Weights for Future Inference\n",
        "\n",
        "Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"
      ],
      "metadata": {
        "id": "_uPq9mVgiBql"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import files\n",
        "files.download('/content/ScaledYOLOv4/runs/exp0_yolov4-csp-results/weights/best_yolov4-csp-results.pt')"
      ],
      "outputs": [],
      "metadata": {
        "id": "YH4CTzDRh00g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# FIN"
      ],
      "outputs": [],
      "metadata": {
        "id": "RtMDmOeN_0ld"
      }
    }
  ]
}