{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import os\r\n",
                "import scipy.io\r\n",
                "import pandas as pd\r\n",
                "import numpy as np\r\n",
                "import cv2\r\n",
                "from PIL import Image\r\n",
                "import shutil\r\n",
                "from pathlib import Path\r\n",
                "import zipfile\r\n",
                "\r\n",
                "# Convertir numpy array en una lista para cada fila\r\n",
                "def get_rows(img_names, labels):\r\n",
                "    rows = []\r\n",
                "    # enumerate(img_names) -> iterador con estructura (indice, array(['nombre_imagen.jpg'])) \r\n",
                "    for index, img_name in enumerate(img_names):\r\n",
                "        for label in labels[index]:\r\n",
                "            # print(index)\r\n",
                "            # print(img_name.item())\r\n",
                "            row = [img_name.item()]\r\n",
                "            row.extend(label) # concatena las etiquetas\r\n",
                "            rows.append(row)\r\n",
                "    return rows\r\n",
                "\r\n",
                "# Convierte el archivo LabelTrainAll.mat en un DataFrame de pandas\r\n",
                "def make_train_data():\r\n",
                "    '''\r\n",
                "    readme-train.txt\r\n",
                "\r\n",
                "    MAFA training set\r\n",
                "    1) images folder puts the 25876 image files; \r\n",
                "    2) the label is stored in LabelTrainAll.mat,\r\n",
                "    3) the format is stored in a 18d array (x,y,w,h, x1,y1,x2,y2, x3,y3,w3,h3, occ_type, occ_degree, gender, race, orientation, x4,y4,w4,h4),  where        \r\n",
                "        (a) (x,y,w,h) is the bounding box of a face, \r\n",
                "        (b) (x1,y1,x2,y2) is the position of two eyes.\r\n",
                "        (c) (x3,y3,w3,h3) is the bounding box of the occluder. Note that (x3,y3) is related to the face bounding box position (x,y)\r\n",
                "        (d) occ_type stands for the occluder type and has: 1 for simple, 2 for complex and 3 for human body.\r\n",
                "        (e) occ_degree stands for the number of occluded face parts\r\n",
                "        (f) gender and race stand for the gender and race of one face\r\n",
                "        (g) orientation stands for the face orientation/pose, and has: 1-left, 2-left frontal, 3-frontal, 4-right frontal, 5-right\r\n",
                "        (h) (x4,y4,w4,h4) is the bounding box of the glasses and is set to (-1,-1,-1,-1) when no glasses.  Note that (x4,y4) is related to the face bounding box position (x,y)\r\n",
                "\r\n",
                "    If any question, please contact me. (geshiming@iie.ac.cn)\r\n",
                "    '''\r\n",
                "\r\n",
                "    train = scipy.io.loadmat('LabelTrainAll.mat') # dictionary with variable names as keys, and loaded matrices as values.\r\n",
                "    # print(train.keys()) # dict_keys(['__header__', '__version__', '__globals__', 'label_train'])\r\n",
                "    train_labels = train['label_train'][0] # array de (25876,) elementos\r\n",
                "    img_names = train_labels['imgName']\r\n",
                "    labels = train_labels['label'] # 21 labels\r\n",
                "    column_name = [ 'image_name'\r\n",
                "                ,'x'\r\n",
                "                ,'y'\r\n",
                "                ,'w'\r\n",
                "                ,'h'\r\n",
                "                ,'x1'\r\n",
                "                ,'y1'\r\n",
                "                ,'x2'\r\n",
                "                ,'y2'\r\n",
                "                ,'x3'\r\n",
                "                ,'y3'\r\n",
                "                ,'w3'\r\n",
                "                ,'h3'\r\n",
                "                ,'occ_type'\r\n",
                "                ,'occ_degree'\r\n",
                "                ,'gender'\r\n",
                "                ,'race'\r\n",
                "                ,'orientation'\r\n",
                "                ,'x4'\r\n",
                "                ,'y4'\r\n",
                "                ,'w4'\r\n",
                "                ,'h4']\r\n",
                "    rows = get_rows(img_names, labels)\r\n",
                "    return pd.DataFrame(data=rows, columns=column_name)\r\n",
                "\r\n",
                "# Convierte el archivo LabelTestAll.mat en un DataFrame de pandas\r\n",
                "def make_test_data():\r\n",
                "    '''\r\n",
                "        MAFA-Label-Test/readme-test.txt\r\n",
                "\r\n",
                "        MAFA testing set\r\n",
                "        1) images folder puts the 4935 image files; \r\n",
                "        2) the label is stored in LabelTestAll.mat,\r\n",
                "        3) the format is stored in a 18d array (x,y,w,h,face_type,x1,y1,w1,h1, occ_type, occ_degree, gender, race, orientation, x2,y2,w2,h2),  where              \r\n",
                "            (a) (x,y,w,h) is the bounding box of a face, \r\n",
                "            (b) face_type stands for the face type and has: 1 for masked face, 2 for unmasked face and 3 for invalid face.\r\n",
                "            (c) (x1,y1,w1,h1) is the bounding box of the occluder. Note that (x1,y1) is related to the face bounding box position (x,y)\r\n",
                "            (d) occ_type stands for the occluder type and has: 1 for simple, 2 for complex and 3 for human body.\r\n",
                "            (e) occ_degree stands for the number of occluded face parts\r\n",
                "            (f) gender and race stand for the gender and race of one face\r\n",
                "            (g) orientation stands for the face orientation/pose, and has: 1-left, 2-left frontal, 3-frontal, 4-right frontal, 5-right\r\n",
                "            (h) (x2,y2,w2,h2) is the bounding box of the glasses and is set to (-1,-1,-1,-1) when no glasses.  Note that (x2,y2) is related to the face bounding box position (x,y)\r\n",
                "\r\n",
                "        If any question, please contact me. (geshiming@iie.ac.cn)\r\n",
                "    '''\r\n",
                "\r\n",
                "    test = scipy.io.loadmat('LabelTestAll.mat')\r\n",
                "    # print(test.keys())\r\n",
                "    test_labels = test['LabelTest'][0]\r\n",
                "    img_names = test_labels['name']\r\n",
                "    labels = test_labels['label']\r\n",
                "    column_name = [ 'image_name',\r\n",
                "            'x',\r\n",
                "            'y',\r\n",
                "            'w',\r\n",
                "            'h',\r\n",
                "            'face_type',\r\n",
                "            'x1',\r\n",
                "            'y1',\r\n",
                "            'w1',\r\n",
                "            'h1', \r\n",
                "            'occ_type', \r\n",
                "            'occ_degree', \r\n",
                "            'gender', \r\n",
                "            'race', \r\n",
                "            'orientation', \r\n",
                "            'x2',\r\n",
                "            'y2',\r\n",
                "            'w2',\r\n",
                "            'h2']\r\n",
                "    rows = get_rows(img_names, labels)\r\n",
                "    return pd.DataFrame(data=rows, columns=column_name)\r\n",
                "'''\r\n",
                " Pasar bounding box de MAFA al formato de YOLO, el formato de yolo es el siguiente:\r\n",
                "     <object-class> - integer number of object from 0 to (classes-1)\r\n",
                "     <x> <y> <width> <height> - float values relative to width and height of image, it can be equal from (0.0 to 1.0]\r\n",
                "     for example: <x> = <absolute_x> / <image_width> or <height> = <absolute_height> / <image_height>\r\n",
                "     atention: <x> <y> - are center of rectangle (are not top-left corner)\r\n",
                "'''\r\n",
                "# Pasar el formato del bounding box de MAFA al formato de YOLO\r\n",
                "def mafa_to_yolo(img, x,y,w,h):\r\n",
                "    img_width, img_height = img # width, height = im.size \r\n",
                "\r\n",
                "    yolo_x = (x+(w /2)) / img_width\r\n",
                "    yolo_y = (y+(h /2)) / img_height\r\n",
                "\r\n",
                "    yolo_w = w / img_width\r\n",
                "    yolo_h = h / img_height\r\n",
                "\r\n",
                "    if yolo_x > 1.0:\r\n",
                "        w = img_width - x\r\n",
                "        yolo_x = (x+(w /2)) / img_width\r\n",
                "    if yolo_y > 1.0:\r\n",
                "        h = img_height - y\r\n",
                "        yolo_y = (y+(h /2)) / img_height\r\n",
                "\r\n",
                "    return yolo_x, yolo_y, yolo_w, yolo_h\r\n",
                "\r\n",
                "# Pasar el formato del bounding box de YOLO al formato de MAFA\r\n",
                "def yolo_to_mafa(img, x,y,w,h):\r\n",
                "    img_height, img_width = img # (height, width) # CV2 # height, width, channels = img.shape\r\n",
                "    if x > 0:\r\n",
                "        x = (x - (w/2)) * img_width\r\n",
                "    if y > 0:\r\n",
                "        y = (y - (h/2)) * img_height\r\n",
                "    w = w * img_width\r\n",
                "    h = h * img_height\r\n",
                "\r\n",
                "    x = int(x)\r\n",
                "    y = int(y)\r\n",
                "    w = int(w)\r\n",
                "    h = int(h)\r\n",
                "    return x, y, w, h\r\n",
                "\r\n",
                "# Cambiar el color del Bounding box dependiendo del label, cv2 usa formato BGR\r\n",
                "def get_color(label):\r\n",
                "    if label == 'Mask':\r\n",
                "        return (0,255,0) # green\r\n",
                "    elif label == 'No mask':\r\n",
                "        return (0,0,255) # red\r\n",
                "    elif label == 'Mask incorrect':\r\n",
                "        return (0,255,255) # yellow\r\n",
                "\r\n",
                "# Dibujar el bounding box, bb es una tupla (x,y,w,h) con el formato de MAFA\r\n",
                "def draw_bb(row, img):\r\n",
                "    x = int(row[1])\r\n",
                "    y = int(row[2])\r\n",
                "    w = int(row[3])\r\n",
                "    h = int(row[4])\r\n",
                "    label = row[5]\r\n",
                "    color = get_color(label)\r\n",
                "\r\n",
                "    cv2.rectangle(img,(x,y),(x+w,y+h),color,2) # x,y -> top-left, x+w, y+h -> botton-right \r\n",
                "    cv2.putText(img,'type: '+(row['occ_type']),(x,y+h+10),0,0.3,color)\r\n",
                "    cv2.putText(img,'degree: '+(str(row['occ_degree'])),(x,y+h+20),0,0.3,color)\r\n",
                "    cv2.putText(img,'label: '+label, (x,y+h+30),0,0.3,color)\r\n",
                "\r\n",
                "    # cv2.circle(img, (x+int(w/2), y+int(h/2)), radius=4, color=(0, 0, 255), thickness=-1) \r\n",
                "\r\n",
                "    return img\r\n",
                "\r\n",
                "def resize_and_padding(img, resize):\r\n",
                "    # source: https://jdhao.github.io/2017/11/06/resize-image-to-square-with-padding/\r\n",
                "    old_size = img.shape[:2] # old_size is in (height, width) format\r\n",
                "\r\n",
                "    ratio = float(resize)/max(old_size)\r\n",
                "    new_size = tuple([int(x*ratio) for x in old_size])\r\n",
                "\r\n",
                "    # new_size should be in (width, height) format\r\n",
                "\r\n",
                "    img = cv2.resize(img, (new_size[1], new_size[0]))\r\n",
                "\r\n",
                "    delta_w = resize - new_size[1]\r\n",
                "    delta_h = resize - new_size[0]\r\n",
                "    top, bottom = delta_h//2, delta_h-(delta_h//2)\r\n",
                "    left, right = delta_w//2, delta_w-(delta_w//2)\r\n",
                "\r\n",
                "    color = [0, 0, 0]\r\n",
                "    new_img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT,\r\n",
                "        value=color)\r\n",
                "    return new_img\r\n",
                "\r\n",
                "def get_occluder_names(df):\r\n",
                "    occluder_type = {\r\n",
                "        1: \"Simple\",\r\n",
                "        2: \"Complex\",\r\n",
                "        3: \"Human body\",\r\n",
                "        -1: \"Unknown\"\r\n",
                "    }\r\n",
                "    df = df.replace({'occ_type': occluder_type})\r\n",
                "    return df\r\n",
                "\r\n",
                "def get_label(row):\r\n",
                "    try:\r\n",
                "        face_type = row['face_type']\r\n",
                "        if face_type == 1.0:\r\n",
                "            return 1, 'Mask'\r\n",
                "        elif face_type == 2.0:\r\n",
                "            return 0, 'No mask'\r\n",
                "    except:\r\n",
                "        pass\r\n",
                "    occ_type = row['occ_type']\r\n",
                "    occ_degree = row['occ_degree']\r\n",
                "    # print(occ_type(occ_degree))\r\n",
                "    if occ_type == 'Human body':\r\n",
                "        return 0, 'No mask'\r\n",
                "    elif occ_type != 'Human body' and occ_degree == 3:\r\n",
                "        return 1, 'Mask'\r\n",
                "    elif occ_type == 'Complex' and occ_degree <= 2:\r\n",
                "        return 0 , 'No mask'\r\n",
                "    elif occ_type == 'Simple' and occ_degree <= 2:\r\n",
                "        return 2, 'Mask incorrect'\r\n",
                "    else:\r\n",
                "        return -1, 'No label'    \r\n",
                "    \r\n",
                "\r\n",
                "def mafa_to_yolo_labels(df, split):\r\n",
                "    label_path = split+'/labels/'\r\n",
                "    image_path = 'images/'\r\n",
                "    image_list = []\r\n",
                "    for f in os.listdir(label_path):\r\n",
                "        os.remove(os.path.join(label_path, f))\r\n",
                "    for index, row in df.iterrows():\r\n",
                "        with open(label_path+row.image_name[:-4]+'.txt','a+') as f:\r\n",
                "            try:\r\n",
                "                # img = cv2.imread(image_path+row.image_name) lento, solo necesito saber las dimensiones no cargar la imagen\r\n",
                "                img = Image.open(image_path+row.image_name)\r\n",
                "                x, y, w, h = mafa_to_yolo(img.size, row.x, row.y, row.w, row.h)\r\n",
                "                img.close()\r\n",
                "                label, _ = get_label(row)\r\n",
                "                for i in x, y, w, h:\r\n",
                "                    write = True\r\n",
                "                    if not(0.0 <= i < 1.0):\r\n",
                "                        write = False\r\n",
                "                        break # Algunas anotaciones de los test estan mal y las x, y son mayores que el tamanio de la imagen \r\n",
                "                if write:\r\n",
                "                    f.write(\"%i %f %f %f %f\\n\"%(label, x, y, w, h))\r\n",
                "                    image_list.append(row.image_name)\r\n",
                "            except FileNotFoundError:\r\n",
                "                print(\"Image \"+ image_path+row.image_name + \" doesn't exist.\")\r\n",
                "                print(index)\r\n",
                "\r\n",
                "    # crear un archivo txt con la ruta de todas las imagenes\r\n",
                "    image_list = list(set(image_list)) # eliminar duplicados\r\n",
                "    # with open(split+'/images.txt', 'w') as f:\r\n",
                "    #     for img in image_list:\r\n",
                "    #         img_path = '../MAFAtoYOLO/images/'+img\r\n",
                "    #         f.write(\"%s\\n\" % img_path)\r\n",
                "\r\n",
                "    # copiar las imagenes a la carpeta correspondiente\r\n",
                "    image_list = list(df.image_name.unique())\r\n",
                "    move_images(source_dir='images', target_dir=split+'/images', image_list=image_list)\r\n",
                "\r\n",
                "def visualize_dataset(df):\r\n",
                "    prev_img = df.iloc[0]['image_name']\r\n",
                "    img = cv2.imread('images/'+prev_img)\r\n",
                "    for index, row in df.iterrows():\r\n",
                "        print(row)\r\n",
                "        _, label_name = get_label(row)            \r\n",
                "        if prev_img != row['image_name']:\r\n",
                "            img = resize_and_padding(img, 1280)\r\n",
                "            cv2.imshow(row['image_name'], img)\r\n",
                "            cv2.show()\r\n",
                "            prev = img\r\n",
                "            img = cv2.imread('./images/'+row['image_name'])\r\n",
                "            img = draw_bb(row, img)\r\n",
                "        else:\r\n",
                "            img = draw_bb(row, img)\r\n",
                "        key = cv2.waitKey(0)\r\n",
                "        if key == ord('a'):\r\n",
                "            cv2.imshow('prev', prev)\r\n",
                "            cv2.show() \r\n",
                "            print(row['image_name'])\r\n",
                "            key = cv2.waitKey(0)\r\n",
                "        elif key == 27: # escape\r\n",
                "            break\r\n",
                "        cv2.destroyAllWindows()\r\n",
                "        prev_img = row['image_name']\r\n",
                "\r\n",
                "def visualize_img(row):\r\n",
                "    # create pandas dataframe\r\n",
                "    df = pd.DataFrame(data = row)\r\n",
                "    visualize_dataset(df)\r\n",
                "\r\n",
                "def draw_yolo_bb(img, row):\r\n",
                "    img_size = img.shape[:2]\r\n",
                "    print(img_size)\r\n",
                "    \r\n",
                "    label = row[0] \r\n",
                "\r\n",
                "    x = float(row[1])\r\n",
                "    y = float(row[2])\r\n",
                "    w = float(row[3])\r\n",
                "    h = float(row[4])\r\n",
                "\r\n",
                "    print(x, y, w, h)\r\n",
                "    x, y, w, h = yolo_to_mafa(img_size, x, y, w, h)\r\n",
                "    print(x, y, w, h)\r\n",
                "\r\n",
                "    img = cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\r\n",
                "    img = cv2.circle(img, (x, y), radius=4, color=(0, 0, 255), thickness=-1)\r\n",
                "    img = cv2.putText(img, 'label: '+ label, (x,y+h+10), 0,0.3, (0,255,0))\r\n",
                "\r\n",
                "    return img\r\n",
                "\r\n",
                "def get_yolo_labels(label_path):\r\n",
                "    rows = []\r\n",
                "    with open(label_path, 'r') as f:\r\n",
                "        for line in f:\r\n",
                "            line = line.split(' ')\r\n",
                "            img_name = label_path.split('\\\\')[-1][:-4]+'.jpg'\r\n",
                "            label = line[0]\r\n",
                "            x = line[1]\r\n",
                "            y = line[2]\r\n",
                "            w = line[3]\r\n",
                "            h = line[4][:-1]\r\n",
                "            row = [label, x, y, w, h]\r\n",
                "            rows.append(row)\r\n",
                "    return pd.DataFrame(data=rows, columns=['label', 'x','y','w','h'])\r\n",
                "\r\n",
                "def add_label_column(df):\r\n",
                "    label_list = []\r\n",
                "    for _, row in df.iterrows():\r\n",
                "        _, label_name = get_label(row)\r\n",
                "        label_list.append(label_name)\r\n",
                "    return label_list\r\n",
                "\r\n",
                "def data_check(df):\r\n",
                "    total = len(df)\r\n",
                "    \r\n",
                "    mask = (df['label'] == 'Mask').sum()\r\n",
                "    mask_incorrect = (df['label'] == 'Mask incorrect').sum()\r\n",
                "    no_mask = (df['label'] == 'No mask').sum()\r\n",
                "    no_label = (df['label'] == 'No label').sum()\r\n",
                "\r\n",
                "    print('Dataset files: ', total)\r\n",
                "    print('Number of Mask : %i / %i, %f %%' % (mask, total, mask*100/total))\r\n",
                "    print('Number of Mask incorrect :  %i / %i, %f %%' % (mask_incorrect, total, mask_incorrect*100/total))\r\n",
                "    print('Number of No mask :  %i / %i, %f %%' % (no_mask, total, no_mask*100/total))\r\n",
                "    print('Number of No Mask + Mask incorrect :  %i / %i, %f %%' % ((no_mask+mask_incorrect), total, (no_mask+mask_incorrect)*100/total))\r\n",
                "    print('Number of No label:  %i / %i, %f %%' % (no_label, total, no_label*100/total))\r\n",
                "\r\n",
                "def train_fix_label(df):\r\n",
                "    df[df['occ_type']=='-1'].replace({'occ_type': 'Simple', 'occ_degree': 3})\r\n",
                "    df[df['occ_degree']=='-1']\r\n",
                "    df.loc[521,'occ_type'] = 'Simple'\r\n",
                "    df.loc[521,'occ_degree'] = 3\r\n",
                "    df.loc[1381,'occ_type'] = 'Simple'\r\n",
                "    df.loc[1381,'occ_degree'] = 3\r\n",
                "    return df\r\n",
                "\r\n",
                "# Borra imagenes del dataset las cuales no tienen bounding boxes\r\n",
                "def test_fix_label(df):\r\n",
                "    # row = test.loc[4448]\r\n",
                "    # img = Image.open('test/images/'+row.image_name)\r\n",
                "    # _, img_height = img.size # width, height = im.size \r\n",
                "    # df.loc[4448, 'h'] = img_height - row.y\r\n",
                "    images_index = [1627, 5851, 5852, 5853, 5854, 7202, 4898, 159]\r\n",
                "    print(df)\r\n",
                "    for i in images_index:\r\n",
                "        row = df.loc[i]\r\n",
                "        print(row)\r\n",
                "        visualize_img(row)\r\n",
                "        \r\n",
                "    df = df.drop(index=[1627, 5851, 5852, 5853, 5854, 7202, 4898, 159])\r\n",
                "    return df\r\n",
                "\r\n",
                "# Crea la estructura de carpetas que usa YOLO\r\n",
                "'''\r\n",
                "Primero mover todas las imagenes(train/images y test/images) a carpeta comun: images\r\n",
                "Crear 3 tipos de carpetas donde se guardaran los datos: train, test y valid\r\n",
                "La estructura seria la siguiente:\r\n",
                "/parent_folder\r\n",
                "    /MAFAtoYOLO\r\n",
                "        /images\r\n",
                "        /train/labels/\r\n",
                "        /train/images.txt\r\n",
                "        /val/labels/\r\n",
                "        /val/images.txt\r\n",
                "        /test/labels/\r\n",
                "        /test/images.txt\r\n",
                "    /yolo\r\n",
                "'''\r\n",
                "def reset():\r\n",
                "    # delete images files and folder\r\n",
                "    for folder in ['images', 'train', 'test', 'val']:\r\n",
                "        if os.path.exists(folder):\r\n",
                "            shutil.rmtree(folder)\r\n",
                "    # remove .mat files\r\n",
                "    for file in os.listdir('.'):\r\n",
                "        if file.endswith('.mat'):\r\n",
                "            os.remove(file)\r\n",
                "    # unzip mafa.zip\r\n",
                "    # zip_ref = zipfile.ZipFile('mafa.zip', 'r')\r\n",
                "    # zip_ref.extractall('.')\r\n",
                "    # zip_ref.close()\r\n",
                "    os.system('unzip -q MAFA.zip')\r\n",
                "\r\n",
                "def create_yolo_structure():\r\n",
                "    # carpetas donde iran las imagenes\r\n",
                "    os.mkdir('images')\r\n",
                "    # mover todas las imagenes a esa carpeta\r\n",
                "    move_images('train/images', 'images')\r\n",
                "    move_images('test/images', 'images')\r\n",
                "    # crear carpetas para train, val y test\r\n",
                "    # os.mkdir('train')\r\n",
                "    os.mkdir('val')\r\n",
                "    # os.mkdir('test')\r\n",
                "    # carpetas donde iran las imagenes\r\n",
                "    # os.mkdir('train/images')\r\n",
                "    os.mkdir('val/images')\r\n",
                "    # os.mkdir('test/images')\r\n",
                "    # carpetas donde iran las anotaciones\r\n",
                "    os.mkdir('train/labels')\r\n",
                "    os.mkdir('val/labels')\r\n",
                "    os.mkdir('test/labels')\r\n",
                "\r\n",
                "# Mover las imagenes de un directorio a otro\r\n",
                "def move_images(source_dir, target_dir, image_list = []):\r\n",
                "    if not os.path.exists(target_dir):\r\n",
                "        os.mkdir(target_dir)\r\n",
                "    for image in image_list if image_list else os.listdir(source_dir):\r\n",
                "        try:\r\n",
                "            shutil.move(os.path.join(source_dir, image), target_dir)\r\n",
                "        except FileNotFoundError:\r\n",
                "            print('File not found: ', os.path.join(source_dir, image))\r\n",
                "\r\n",
                "# copy all files from one folder to another\r\n",
                "def copy_images(source_dir, target_dir, image_list = []):\r\n",
                "    if not os.path.exists(target_dir):\r\n",
                "        os.mkdir(target_dir)\r\n",
                "    for image in image_list if image_list else os.listdir(source_dir):\r\n",
                "        try:\r\n",
                "            shutil.copy(os.path.join(source_dir, image), target_dir)\r\n",
                "        except FileNotFoundError:\r\n",
                "            print('File not found: ', os.path.join(source_dir, image))\r\n",
                "\r\n",
                "\r\n",
                "def make_yolo_labels(train, validation, test):\r\n",
                "    print('Making yolo labels for training data...')\r\n",
                "    mafa_to_yolo_labels(train, 'train')\r\n",
                "    print('Done')\r\n",
                "\r\n",
                "    print('Making yolo labels for validation data...')\r\n",
                "    mafa_to_yolo_labels(validation, 'val')\r\n",
                "    print('Done')\r\n",
                "\r\n",
                "    print('Making yolo labels for test data...')\r\n",
                "    mafa_to_yolo_labels(test, 'test')\r\n",
                "    print('Done')\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 1 - Crear la estructura del proyecto\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "create_yolo_structure()\r\n"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "FileExistsError",
                    "evalue": "[Errno 17] File exists: 'images'",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-5-edd911f8a1e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_yolo_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m<ipython-input-4-babdb272db68>\u001b[0m in \u001b[0;36mcreate_yolo_structure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_yolo_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;31m# carpetas donde iran las imagenes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m     \u001b[0;31m# mover todas las imagenes a esa carpeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mmove_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train/images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'images'"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 2 - Pasar las anotaciones del .mat a un pandas dataframe\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "train = make_train_data()\r\n",
                "test = make_test_data()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 3 - Cambiar las anotaciones numericas a strings\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "train = get_occluder_names(train)\r\n",
                "test = get_occluder_names(test)\r\n",
                "test = test.astype({'occ_degree': int}) # test[occ_degree] tiene valores decimales, pasar a int como en train"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 5 - Insertar una columna con las etiquetas: Mask, No Mask, Mask Incorrect\n",
                "# dependiendo del tipo de oclusion y su grado\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "train.insert(loc=5, column='label', value=add_label_column(train))\r\n",
                "test.insert(loc=5, column='label', value=add_label_column(test))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 4 - Corregir imagenes mal anotadas\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "train = train_fix_label(train)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "train.columns"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "Error",
                    "evalue": "Session cannot generate requests",
                    "traceback": [
                        "Error: Session cannot generate requests",
                        "at w.executeCodeCell (c:\\Users\\Rodrigo\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.2041215044\\out\\client\\extension.js:52:301310)",
                        "at w.execute (c:\\Users\\Rodrigo\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.2041215044\\out\\client\\extension.js:52:300703)",
                        "at w.start (c:\\Users\\Rodrigo\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.2041215044\\out\\client\\extension.js:52:296367)",
                        "at runMicrotasks (<anonymous>)",
                        "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
                        "at t.CellExecutionQueue.executeQueuedCells (c:\\Users\\Rodrigo\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.2041215044\\out\\client\\extension.js:52:311160)",
                        "at t.CellExecutionQueue.start (c:\\Users\\Rodrigo\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.2041215044\\out\\client\\extension.js:52:310700)"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "visualize_dataset(train)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "image_name     train_00000001.jpg\n",
                        "x                              95\n",
                        "y                             160\n",
                        "w                              91\n",
                        "h                              91\n",
                        "label                        Mask\n",
                        "x1                            113\n",
                        "y1                            177\n",
                        "x2                            158\n",
                        "y2                            172\n",
                        "x3                              7\n",
                        "y3                             26\n",
                        "w3                             82\n",
                        "h3                             89\n",
                        "occ_type                   Simple\n",
                        "occ_degree                      3\n",
                        "gender                          1\n",
                        "race                            1\n",
                        "orientation                     3\n",
                        "x4                             -1\n",
                        "y4                             -1\n",
                        "w4                             -1\n",
                        "h4                             -1\n",
                        "Name: 0, dtype: object\n",
                        "image_name     train_00000002.jpg\n",
                        "x                             107\n",
                        "y                              82\n",
                        "w                              66\n",
                        "h                              66\n",
                        "label                        Mask\n",
                        "x1                            129\n",
                        "y1                             95\n",
                        "x2                            156\n",
                        "y2                             96\n",
                        "x3                              5\n",
                        "y3                             17\n",
                        "w3                             65\n",
                        "h3                             56\n",
                        "occ_type                  Complex\n",
                        "occ_degree                      3\n",
                        "gender                          1\n",
                        "race                            1\n",
                        "orientation                     3\n",
                        "x4                             -1\n",
                        "y4                             -1\n",
                        "w4                             -1\n",
                        "h4                             -1\n",
                        "Name: 1, dtype: object\n"
                    ]
                },
                {
                    "output_type": "error",
                    "ename": "AttributeError",
                    "evalue": "module 'cv2' has no attribute 'show'",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                        "\u001b[1;32m<ipython-input-6-857c30752035>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvisualize_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[1;32m<ipython-input-1-3467c2a8c87a>\u001b[0m in \u001b[0;36mvisualize_dataset\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresize_and_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1280\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m             \u001b[0mprev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./images/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'show'"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "test = test_fix_label(test)\r\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "              image_name       x       y      w      h  face_type    x1  \\\n",
                        "0      test_00000001.jpg  2694.0  1211.0  353.0  353.0        1.0   9.0   \n",
                        "1      test_00000001.jpg  1754.0  1449.0   68.0   68.0        3.0  -1.0   \n",
                        "2      test_00000002.jpg   113.0    95.0  226.0  226.0        1.0   9.0   \n",
                        "3      test_00000003.jpg   352.0   114.0  151.0  151.0        1.0  17.0   \n",
                        "4      test_00000003.jpg   799.0   217.0  139.0  139.0        2.0  -1.0   \n",
                        "...                  ...     ...     ...    ...    ...        ...   ...   \n",
                        "10028  test_00004931.jpg   135.0    51.0  285.0  285.0        1.0  54.0   \n",
                        "10029  test_00004932.jpg    38.0   120.0  285.0  285.0        1.0  30.0   \n",
                        "10030  test_00004933.jpg    80.0   121.0  245.0  245.0        1.0  50.0   \n",
                        "10031  test_00004934.jpg   148.0   266.0  276.0  276.0        1.0  38.0   \n",
                        "10032  test_00004935.jpg   110.0    98.0  318.0  318.0        1.0  73.0   \n",
                        "\n",
                        "          y1     w1     h1 occ_type  occ_degree  gender  race  orientation  \\\n",
                        "0      105.0  144.0  337.0  Complex           3     2.0   2.0          1.0   \n",
                        "1       -1.0   -1.0   -1.0  Unknown          -1    -1.0  -1.0         -1.0   \n",
                        "2       71.0  181.0  221.0   Simple           3     1.0   2.0          3.0   \n",
                        "3       45.0  137.0  135.0   Simple           3     2.0   2.0          3.0   \n",
                        "4       -1.0   -1.0   -1.0  Unknown          -1    -1.0  -1.0         -1.0   \n",
                        "...      ...    ...    ...      ...         ...     ...   ...          ...   \n",
                        "10028  108.0  280.0  267.0   Simple           3     2.0   2.0          3.0   \n",
                        "10029   93.0  255.0  258.0   Simple           3     2.0   2.0          3.0   \n",
                        "10030   81.0  238.0  242.0   Simple           3     2.0   2.0          3.0   \n",
                        "10031   68.0  265.0  248.0   Simple           3     2.0   2.0          3.0   \n",
                        "10032  124.0  313.0  302.0   Simple           3     2.0   2.0          3.0   \n",
                        "\n",
                        "        x2   y2   w2   h2  \n",
                        "0     -1.0 -1.0 -1.0 -1.0  \n",
                        "1     -1.0 -1.0 -1.0 -1.0  \n",
                        "2     -1.0 -1.0 -1.0 -1.0  \n",
                        "3     -1.0 -1.0 -1.0 -1.0  \n",
                        "4     -1.0 -1.0 -1.0 -1.0  \n",
                        "...    ...  ...  ...  ...  \n",
                        "10028 -1.0 -1.0 -1.0 -1.0  \n",
                        "10029 -1.0 -1.0 -1.0 -1.0  \n",
                        "10030 -1.0 -1.0 -1.0 -1.0  \n",
                        "10031 -1.0 -1.0 -1.0 -1.0  \n",
                        "10032 -1.0 -1.0 -1.0 -1.0  \n",
                        "\n",
                        "[10033 rows x 19 columns]\n",
                        "image_name     test_00000900.jpg\n",
                        "x                            116\n",
                        "y                            345\n",
                        "w                             62\n",
                        "h                             62\n",
                        "face_type                      2\n",
                        "x1                            -1\n",
                        "y1                            -1\n",
                        "w1                            -1\n",
                        "h1                            -1\n",
                        "occ_type                 Unknown\n",
                        "occ_degree                    -1\n",
                        "gender                        -1\n",
                        "race                          -1\n",
                        "orientation                   -1\n",
                        "x2                            -1\n",
                        "y2                            -1\n",
                        "w2                            -1\n",
                        "h2                            -1\n",
                        "Name: 1627, dtype: object\n"
                    ]
                },
                {
                    "output_type": "error",
                    "ename": "KeyError",
                    "evalue": "'image_name'",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
                        "\u001b[0;32m/home/rodrigo/miniconda3/envs/directml/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
                        "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
                        "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
                        "\u001b[0;31mKeyError\u001b[0m: 'image_name'",
                        "\nThe above exception was the direct cause of the following exception:\n",
                        "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-14-0db47c4cb229>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_fix_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m<ipython-input-10-5013d9293d44>\u001b[0m in \u001b[0;36mtest_fix_label\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mvisualize_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1627\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5851\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5852\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5853\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5854\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7202\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4898\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m159\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m<ipython-input-10-5013d9293d44>\u001b[0m in \u001b[0;36mvisualize_img\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;31m# create pandas dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m     \u001b[0mvisualize_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdraw_yolo_bb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m<ipython-input-10-5013d9293d44>\u001b[0m in \u001b[0;36mvisualize_dataset\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvisualize_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m     \u001b[0mprev_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mprev_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/home/rodrigo/miniconda3/envs/directml/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/home/rodrigo/miniconda3/envs/directml/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/home/rodrigo/miniconda3/envs/directml/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mKeyError\u001b[0m: 'image_name'"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "\r\n",
                "\r\n",
                "# 5 - Insertar una columna con las etiquetas: Mask, No Mask, Mask Incorrect\r\n",
                "# dependiendo del tipo de oclusion y su grado\r\n",
                "train.insert(loc=5, column='label', value=add_label_column(train))\r\n",
                "test.insert(loc=5, column='label', value=add_label_column(test))\r\n",
                "\r\n",
                "train = train.astype({'label': str})\r\n",
                "\r\n",
                "# dataset = pd.concat([train, test])\r\n",
                "\r\n",
                "\r\n",
                "# x = len(train[train['label'] == 'No label'])\r\n",
                "# y = len(train[train['label'] != 'No label'])\r\n",
                "# print('Total images train: ', x, y, y-x)\r\n",
                "\r\n",
                "# x = len(test[test['label'] == 'No label'])\r\n",
                "# y = len(test[test['label'] != 'No label'])\r\n",
                "# print('Total images test: ', x, y, y-x)\r\n",
                "\r\n",
                "# print(len(train[train['label'] != 'No label']))\r\n",
                "# print(len(train[train['label'] == 'No label']))\r\n",
                "\r\n",
                "\r\n",
                "# train = dataset[dataset['label'] != 'No label']\r\n",
                "# test  = dataset[dataset['label'] == 'No label']\r\n",
                "\r\n",
                "# test_images_name = test.image_name.values\r\n",
                "\r\n",
                "# test  = dataset[dataset['image_name'].isin(test_images_name)]\r\n",
                "# train = dataset[~dataset['image_name'].isin(test_images_name)]\r\n",
                "   \r\n",
                "# race_1 = dataset[dataset['race'] == -1.] # 1.0 -> caucasico, 2.0 -> oriental/asitico, 3.0 -> afroamericano\r\n",
                "train = train[train['label'] != 'No label']\r\n",
                "test =  test[test['label'] != 'No label']\r\n",
                "\r\n",
                "test_half = int(len(test)/2)\r\n",
                "train = pd.concat([train, test[:test_half]])\r\n",
                "test = test[test_half+1:]\r\n",
                "\r\n",
                "dataset = pd.concat([train, test])\r\n",
                "# Quiero que el dataset de entrenamiento este compuesto por todas las imagenes las cuales:\r\n",
                "# Tenga mas de una bounding box (bb) \r\n",
                "bb_number = train.groupby(['image_name']).size()\r\n",
                "more_than_one = bb_number[bb_number > 1]\r\n",
                "    mask_multiple = train[train['image_name'].isin(more_than_one.index)]\r\n",
                "    # Las mascarillas esten incorrectas\r\n",
                "    mask_incorrect = train[train['label']=='Mask incorrect']\r\n",
                "    # Las personas no lleven mascarillla\r\n",
                "    no_mask = train[train['label']=='No mask']\r\n",
                "    # Y un % de de las imagenes en las que solo sale una mascarilla\r\n",
                "    one = bb_number[bb_number == 1]\r\n",
                "    mask = train[train['image_name'].isin(one.index)]\r\n",
                "\r\n",
                "    mask = mask.sample(frac = 0.05) # 1/5 29733 / 35875, 75.302013 %\r\n",
                "    # Unimos todas las separaciones y este sera el train final\r\n",
                "    print('mask_multiple:', len(mask_multiple))\r\n",
                "    print('mask_incorrect:', len(mask_incorrect))\r\n",
                "    print('no_mask:', len(no_mask))\r\n",
                "\r\n",
                "    # visualize_dataset(mask_incorrect) # mas o menos\r\n",
                "    # visualize_dataset(mask_multiple) # mas o menos\r\n",
                "    # visualize_dataset(train[(train['occ_type'] == 'Complex') & (train['occ_degree'] == 2)]) # mas o menos\r\n",
                "\r\n",
                "    train = pd.concat([mask_multiple, mask_incorrect, no_mask, mask], ignore_index=True)\r\n",
                "    train = train.drop_duplicates()\r\n",
                "\r\n",
                "    # order dataframe by image_name\r\n",
                "    train = train.sort_values(by=['image_name'])\r\n",
                "\r\n",
                "    # Ahora divimos el dataset en 5 partes, antes de ello mezclamos todas las filas para que cada parte sea lo mas aleatoria posible\r\n",
                "    # 3 de las 5 partes sera el dataset para entrenar el model, 1 parte sera para validar y 1 parte para como test \r\n",
                "    split = round(len(train) * .75)    \r\n",
                "    validation = train[split+1:]\r\n",
                "    train = train[:split]\r\n",
                "    # print(train)\r\n",
                "    # print(validation)\r\n",
                "    print('Dataset: %i\\t Train: %i\\t Validation: %i\\t Test: %i' % (len(dataset), len(train), len(validation), len(test)))\r\n",
                "    print('TRAIN:')\r\n",
                "    data_check(train)\r\n",
                "    print('VALIDATION:')\r\n",
                "    data_check(validation)\r\n",
                "    print('TEST:')\r\n",
                "    data_check(test)\r\n",
                "\r\n",
                "    validation = validation[validation.image_name.isin(train.image_name.values)]\r\n",
                "\r\n",
                "    train_img_list = set(train.image_name.values)\r\n",
                "    validation_img_list = set(validation.image_name.values)\r\n",
                "    test_img_list = set(test.image_name.values)\r\n",
                "\r\n",
                "    # pandas pop row if train.image_name in validation\r\n",
                "    # pandas pop row if train.image_name in test\r\n",
                "\r\n",
                "    print('Train comparte imagenes con val o test?')\r\n",
                "    print(any(item in train_img_list for item in validation_img_list))\r\n",
                "    print(any(item in train_img_list for item in test_img_list))\r\n",
                "\r\n",
                "\r\n",
                "    print('Validation comparte imagenes con train o test?')\r\n",
                "    print(any(item in validation_img_list for item in train_img_list))\r\n",
                "    print(any(item in validation_img_list for item in test_img_list))\r\n",
                "\r\n",
                "    print('Test comparte imagenes con train o val?')\r\n",
                "    print(any(item in test_img_list for item in train_img_list))\r\n",
                "    print(any(item in test_img_list for item in validation_img_list))\r\n",
                "\r\n",
                "    # 5 - Pasar los dataframe al formato que usa YOLO para las anotaciones \r\n",
                "    # make_yolo_labels(train, validation, test)"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.5 64-bit ('yolov4-csp': conda)"
        },
        "interpreter": {
            "hash": "a8b7c107a3b4d3e0d1271416a943dcbce33c1390db553fa7d9cd63a19104b0c6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}